{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17097be2-8377-47c0-888b-2edab46bdc3a",
   "metadata": {},
   "source": [
    "# From kaggle link: https://www.kaggle.com/datasets/msambare/fer2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b4cb32c-6ede-458b-ab53-21c4eca1dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8534285e-77b7-49fa-af47-125e35a60f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'happy', 'neutral', 'sad']\n"
     ]
    }
   ],
   "source": [
    "trainPath = r\"dataset\\train\"\n",
    "testPath = r\"dataset\\test\" # add the location of the saved images\n",
    "folderList = os.listdir(trainPath)\n",
    "folderList.sort()\n",
    "print(folderList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2c4e059-51e3-44d9-aa02-b41639ce7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd78017-4538-4d57-ae42-c55d9f16cba2",
   "metadata": {},
   "source": [
    "# Load the train model to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b7a64a-21a4-45f2-8883-51d352634433",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, category in enumerate(folderList):\n",
    "    files = os.listdir(trainPath+\"/\"+category)\n",
    "    for file in files:\n",
    "        print(category+\"/\"+file)\n",
    "        img = cv2.imread(trainPath+\"/\"+category+'/{0}'.format(file),0)\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "print(len(X_train)) # 21005 train images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6efe27-b2ec-4239-9764-7a7f7f209638",
   "metadata": {},
   "source": [
    "# Show the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388195a-87db-4625-b409-1f1c19c2e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = X_train[0]\n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd9801-6824-4346-acae-2988b8a5f7ea",
   "metadata": {},
   "source": [
    "# Check the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368a0eb-ac71-408f-b8c2-cf5b7d2c3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a25ea9aa-31cc-4a20-8eaa-3dda26ee1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "folderList = os.listdir(testPath)\n",
    "folderList.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc3e4cb-288b-4edb-b347-6e2273a46b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, category in enumerate(folderList):\n",
    "    files = os.listdir(testPath+\"/\"+category)\n",
    "    for file in files:\n",
    "        print(category+\"/\"+file)\n",
    "        img = cv2.imread(testPath+\"/\"+category+'/{0}'.format(file),0)\n",
    "        X_test.append(img)\n",
    "        y_test.append(i)\n",
    "\n",
    "print(\"test data:\")\n",
    "print(len(X_test)) # 5212 test images\n",
    "print(len(y_test)) #5212"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962500a2-025a-47a0-b7f6-fce5cdad758b",
   "metadata": {},
   "source": [
    "# Convert the data to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed8a994-3fa4-442a-a196-e33950a3da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, 'float32')\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test, 'float32')\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88ca844c-56b6-4861-b502-26f392c3e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eab970-0e41-4a7f-b1ea-6049cf097a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "numImages = X_train.shape[0]\n",
    "X_train = X_train.reshape(numImages,48,48,1)\n",
    "print(X_train[0])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1190d27-1511-4ce1-bb6a-0d7b31b08dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "numImages = X_test.shape[0]\n",
    "X_test = X_test.reshape(numImages,48,48,1)\n",
    "print(X_test[0])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ba033c6-ff49-46b0-b4a6-ad8169042928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d302c2-4ed2-43d8-b3fd-007bf7f195fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "print(\"# To categorical\")\n",
    "print(y_train)\n",
    "print(y_train.shape)\n",
    "print(y_train[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802fab2-c5a0-4349-a484-6a65b4ae9e24",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed2f13-32e8-44be-836f-fde9dc9216ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (48,48,1)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd191dea-b0bd-4873-8223-e8737c90c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape = input_shape, filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c009ab-6366-420e-9b8f-876e712caa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "batch = 32\n",
    "epochs = 30\n",
    "\n",
    "stepsPerEpoch = np.ceil(len(X_train)/batch)\n",
    "validationsPerEpoch = np.ceil(len(X_test)/batch)\n",
    "\n",
    "stopEarly = EarlyStopping(monitor = 'val_accuracy', patience = 5)\n",
    "history = model.fit(X_train, y_train, batch_size = batch, epochs = epochs, verbose = 1, validation_data = (X_test,y_test),shuffle=True, callbacks = [stopEarly])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690bf87-edc5-4fd4-b718-95f4763241db",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb8b0e-58bb-4849-a4de-fa14074f6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'r', label=\"Train accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Train accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Training and validation Accuracy\")\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59191eb8-70b0-47d6-b02f-470f9b74aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'r', label=\"Train loss\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Train loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title(\"Training and validation Loss\")\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e0aa32-6a51-4ed4-8555-9433a794d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = r\"emotionsdetection.keras\"\n",
    "model.save(modelname)\n",
    "\n",
    "model = tf.keras.models.load_model(\"emotionsdetection.keras\")\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Optimize model size (optional)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model\n",
    "with open(\"detectemotions.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model successfully converted to detectionemotions.tflite\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
